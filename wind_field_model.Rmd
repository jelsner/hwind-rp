---
title: "Hurricane wind field model"
output: html_document
editor_options: 
  chunk_output_type: console
---


## IBTraCS data 

Geometry type LINESTRING

https://www.ncei.noaa.gov/data/international-best-track-archive-for-climate-stewardship-ibtracs/v04r00/access/shapefile/
https://www.ncei.noaa.gov/data/international-best-track-archive-for-climate-stewardship-ibtracs/v04r00/doc/IBTrACS_v04_Technical_Details.pdf

https://www.ncei.noaa.gov/sites/default/files/2021-07/IBTrACS_v04_column_documentation.pdf

Wind speed in knots
```{r}
L <- "https://www.ncei.noaa.gov/data/international-best-track-archive-for-climate-stewardship-ibtracs/v04r00/access/shapefile/IBTrACS.NA.list.v04r00.lines.zip"
  
if(!"IBTrACS.NA.list.v04r00.lines.zip" %in% list.files(here::here("data"))) {
download.file(url = L,
              destfile = here::here("data",
                                    "IBTrACS.NA.list.v04r00.lines.zip"))
unzip(here::here("data", "IBTrACS.NA.list.v04r00.lines.zip"),
      exdir = here::here("data"))
}

Tracks.sf <- sf::st_read(dsn = here::here("data"), 
                         layer = "IBTrACS.NA.list.v04r00.lines") |>
  sf::st_transform(crs = 32616)
```

Average radius to maximum wind 1980-2023. Values of USA_RMW (radius to maximum winds) and USA_EYE (eye diameter) are in nautical miles. To convert to kilometers multiply by 1.852.
```{r}
Tracks.sf |>
  sf::st_drop_geometry() |>
  dplyr::filter(year >= 1980 & year <= 2023) |>
  dplyr::summarize(avgRMW = mean(USA_RMW, na.rm = TRUE) * 1.852,
                   avgEYE = mean(USA_EYE, na.rm = TRUE) * 1.852)
```

Keep only hurricanes since 1980
```{r}
Tracks2.sf <- Tracks.sf |>
  dplyr::filter(year >= 1980) |>
  dplyr::filter(USA_WIND >= 64) |>
  dplyr::select(SID, SEASON, year, month, day, hour, min,
                NAME, SUBBASIN, ISO_TIME,
                USA_WIND, USA_PRES, USA_RMW, USA_EYE, USA_ROCI)
```

Average radius to maximum wind 1980-2023. Values of USA_RMW (radius to maximum winds) and USA_EYE (eye diameter) are in nautical miles. ROCI: Radius of outer closed isobar. To convert to kilometers multiply by 1.852.
```{r}
Tracks2.sf |>
  sf::st_drop_geometry() |>
  dplyr::filter(year >= 1980 & year <= 2023) |>
#  dplyr::group_by(USA_PRES) |>
  dplyr::summarize(avgRMW = mean(USA_RMW, na.rm = TRUE) * 1.852,
                   avgEYE = mean(USA_EYE, na.rm = TRUE) * 1.852,
                   avgROCI = mean(USA_ROCI, na.rm = TRUE) * 1.852)
```

Fill in missing RMW values. Start with pedigree, then use minimum pressure, and finish again with pedigree

```{r}
Tracks2.sf <- Tracks2.sf |>
  dplyr::group_by(SID) |>  # pedigree
  dplyr::mutate(USA_RMW = ifelse(is.na(USA_RMW), mean(USA_RMW, na.rm = TRUE), USA_RMW))

Tracks2.sf <- Tracks2.sf |>
  dplyr::group_by(USA_PRES) |> # minimum pressure
  dplyr::mutate(USA_RMW = ifelse(is.na(USA_RMW), mean(USA_RMW, na.rm = TRUE), USA_RMW))

Tracks2.sf <- Tracks2.sf |>
  dplyr::group_by(SID) |> # pedigree
  dplyr::mutate(USA_RMW = ifelse(is.na(USA_RMW), mean(USA_RMW, na.rm = TRUE), USA_RMW))
```

Add a buffer to the tracks to make segmented swaths

```{r}
Swaths.sf <- Tracks2.sf |>
  sf::st_buffer(dist = Tracks2.sf$USA_RMW * 1852) # 1852 converts to meters

SingleSwaths.sf <- Swaths.sf |>
  dplyr::group_by(SID) |>
  sf::st_combine()

library(tmap)

tmap::tmap_mode("view")

tmap::tm_shape(Swaths.sf) +
  tmap::tm_borders()

```


## Extract the dates of county-level TC center crossings 1980-2023

https://www.census.gov/programs-surveys/geography/guidance/geo-identifiers.html

`USAboundaries` package no longer maintained on CRAN

```{r}
devtools::install_github("ropensci/USAboundariesData")
devtools::install_github("ropensci/USAboundaries")
```

Keep only swaths that intersect the boundary of Florida

```{r}
Boundaries.sf <- USAboundaries::us_states(resolution = "low", states = "FL") |> 
  sf::st_transform(crs = 32616)

X <- Swaths.sf |>
  sf::st_intersects(Boundaries.sf, sparse = FALSE)

Swaths.sf <- Swaths.sf[X, ]

Swaths.sf <- Swaths.sf |>
  dplyr::mutate(Date = lubridate::as_date(ISO_TIME)) # add a m-y-d column
```

Unionize the swath segments by storm ID

```{r}
Swaths2.sf <- Swaths.sf |>
  dplyr::group_by(SID) |>
  dplyr::summarize(Date0 = dplyr::first(Date),
                   NAME = dplyr::first(NAME),
                   geometry = st_union(geometry))
```


I need to expand the data set by adding features based on the increment value of the attribute `Date0`

```{r}
deltaT <- 1   # One day increment
n_new <- 3    # Number of new features (rows) to create for each feature (row) times 2

library(tidyr)

# Expand dataset by adding incremented values
expanded_Swaths.sf <- Swaths2.sf |>
    dplyr::rowwise() |>
    dplyr::mutate(new_features = list(tibble(
                  Dates = Date0 + (-n_new:n_new) * deltaT,
                  sid = SID
                  ))) |>
    unnest(new_features) |>
    dplyr::ungroup() |>
    dplyr::select(-Date0, -SID) # Remove original columns
```

Transform the coordinates to lat/lon

```{r}
expanded_Swaths.sf <- expanded_Swaths.sf |>
  sf::st_transform(crs = 4326)
```




```{r}
Boundaries.sf <- USAboundaries::us_counties(resolution = "low", states = "FL") |> 
  sf::st_transform(crs = 32616)

X <- Swaths.sf |>
  sf::st_intersection(y = Boundaries.sf) |>
  dplyr::select(geoid, name, ISO_TIME, NAME, USA_WIND, USA_PRES) |>
  dplyr::mutate(date = lubridate::as_date(ISO_TIME)) |>
  sf::st_drop_geometry() |>
  dplyr::group_by(geoid, date) |>
  dplyr::summarize(CountyName = dplyr::first(name),
                   Wind_kt = max(USA_WIND),
                   Press_mb = min(USA_PRES))

X |>
  dplyr::group_by(CountyName) |>
  dplyr::summarize(nTC = dplyr::n(),
                   Wmax = max(Wind_kt, na.rm = TRUE),
                   Pmin = min(Press_mb, na.rm = TRUE)) |>
  dplyr::arrange(desc(nTC))
```

## Repeat for census tracts

```{r}
Boundaries.sf <- tidycensus::get_acs(
  geography = "tract",
  variables = "B01003_001",
  state = "FL",
  geometry = TRUE
  ) |>
    sf::st_transform(crs = 32616)

X <- Swaths.sf |>
  sf::st_intersection(y = Boundaries.sf) |>
  dplyr::select(GEOID, NAME.1, ISO_TIME, NAME, USA_WIND, USA_PRES) |>
  dplyr::mutate(date = lubridate::as_date(ISO_TIME),
                StormNameYear = paste0(NAME, "-", lubridate::year(date))) |>
  sf::st_drop_geometry() |>
  dplyr::group_by(GEOID, date) |>
  dplyr::summarize(AreaName = dplyr::first(NAME.1),
                   Wind_kt = max(USA_WIND),
                   Press_mb = min(USA_PRES),
                   StormNameYear = dplyr::first(StormNameYear)) |>
  dplyr::arrange(date, GEOID) |>
  dplyr::left_join(Boundaries.sf, by = "GEOID", keep = FALSE) |>
  sf::st_as_sf()

#write.csv(X, here::here("data", "place-level-TC-winds-pressure"))
```

What storm impacted the most areas?
```{r}
X |> 
  dplyr::group_by(StormNameYear) |>
  dplyr::summarize(nAreasImpacted = dplyr::n()) |>
  dplyr::arrange(desc(nAreasImpacted))
```

## Repeat for city areas (zip code tabulation area, ztca)

```{r}
library(tidycensus)

# valid years are 2000, 2010, and 2020
Boundaries.sf <- get_decennial(
  geography = "zcta",
  variables = "P005003",
  year = 2010,
  state = "FL",  # one state at a time
  geometry = TRUE
  ) |>
  sf::st_transform(crs = 32616)

Boundaries.sf <- get_acs(
  geography = "place",  # cities/metro areas
  variables = "B01003_001",
  year = 2020, #years 2014-2018
  state = c("FL"),
  geometry = TRUE) |>
  sf::st_transform(crs = 32616)


X <- Swaths.sf |>
  sf::st_intersection(y = Boundaries2.sf) |>
  dplyr::select(GEOID, NAME.1, ISO_TIME, NAME, USA_WIND, USA_PRES) |>
  dplyr::mutate(date = lubridate::as_date(ISO_TIME),
                StormNameYear = paste0(NAME, "-", lubridate::year(date))) |>
  sf::st_drop_geometry() |>
  dplyr::group_by(date, GEOID) |>
  dplyr::summarize(CityName = dplyr::first(NAME.1),
                   Wind_kt = max(USA_WIND),
                   Press_mb = min(USA_PRES),
                   StormNameYear = dplyr::first(StormNameYear)) |>
  dplyr::arrange(date, desc(Wind_kt))
```


## Get PRISM rainfall data for Hurricane Kate (1985)

```{r}
library(prism)

prism_set_dl_dir("data/PRISM")

get_prism_dailys(type = "ppt",
                 minDate = "1985-11-21",
                 maxDate = "1985-11-22")

dates <- seq(lubridate::as_date("1985-11-21"), 
             lubridate::as_date("1985-11-22"), 
             by = "day")

file_days <- gsub("-", "", dates)

folder_names <- paste0("PRISM_ppt_stable_4kmD2_", file_days, "_bil/")
file_names <- paste0("PRISM_ppt_stable_4kmD2_", file_days, "_bil.bil")
file_list <- paste0("data/", "PRISM/", folder_names, file_names)

ppt.st <- stars::read_stars(file_list, along = list(time = dates)) |>
  setNames("Precip_mm")

plot(ppt.st)
```

Extract rainfall from space-time `stars` object at a particular target location (e.g., centroid of zip code area).
```{r}
print(ppt.st)

library(sf)
st_crs(ppt.st)

target_location <- st_sfc(st_point(c(-84.28, 30.43)), crs = 4326) 
target_location_transformed <- st_transform(target_location, 
                                            st_crs(ppt.st))

time_series_data <- stars::st_extract(ppt.st, target_location_transformed)
time_series_data$Precip_mm
```

Crop prism rasters to census tracts affected by Kate

```{r}

X2 <- X |>
  dplyr::filter(StormNameYear == "KATE-1985") |>
  sf::st_transform(crs = sf::st_crs(ppt.st))

plot(X2$geometry)

ppt2.st <- ppt.st |>
  sf::st_crop(X2)

plot(ppt2.st)

#must make ppt.st a raster of some type

library(raster)
ppt2.r <- as.raster(ppt2.st)

exactextractr::exact_extract(ppt.st, X2, fun = max)
```




## Repeat for city areas

```{r}
library(tidycensus)

Boundaries2.sf <- get_decennial(geography = "zcta",
                                variables = "B03002_001",
                                year = 2010,
                                geometry = TRUE) |>
  sf::st_transform(crs = 32616)

Boundaries2.sf <- get_acs(geography = "zip code tabulation area", 
                          variables = "B19013_001",
                          summary_var = "B01001_001",
                          geometry = TRUE)


Boundaries2.sf <- get_acs(geography = "place",
                      variables = "B01003_001",
                      state = c("FL", "AL", "MS", "LA", "TX"),
                      geometry = TRUE) |>
    sf::st_transform(crs = 32616)


X <- Tracks.sf |>
  dplyr::filter(year >= 1980) |>
  sf::st_intersection(y = Boundaries2.sf) |>
  dplyr::select(GEOID, NAME.1, ISO_TIME, NAME, USA_WIND, USA_PRES) |>
  dplyr::mutate(date = lubridate::as_date(ISO_TIME),
                StormNameYear = paste0(NAME, "-", lubridate::year(date))) |>
  sf::st_drop_geometry() |>
  dplyr::group_by(date, GEOID) |>
  dplyr::summarize(CityName = dplyr::first(NAME.1),
                   Wind_kt = max(USA_WIND),
                   Press_mb = min(USA_PRES),
                   StormNameYear = dplyr::first(StormNameYear)) |>
  dplyr::arrange(date, desc(Wind_kt))
```


## Find all storms within 100 km of a location

```{r}
point <- sf::st_point(c(-85.3, 29.9))
location.sf <- sf::st_sfc(point, 
                           crs = 4326) |>
  sf::st_transform(crs = 32616) |>
  sf::st_as_sf()

buffer.sf <- location.sf |>
  sf::st_buffer(dist = 100000)

Tracks2.sf <- Tracks.sf |>
  sf::st_intersection(buffer.sf)

Tracks3.sf <- Tracks2.sf[!is.na(Tracks2.sf$USA_ATCFID),]

length(unique(Tracks3.sf$USA_ATCFID))
max(Tracks3.sf$SEASON) - min(Tracks3.sf$SEASON) + 1
```

List the unique storms by `USA_ATCFID` = `track_id`
```{r}
unique(Tracks3.sf$USA_ATCFID)
```

Group by storm ID and find the fastest wind
```{r}
X <- Tracks3.sf |>
  sf::st_drop_geometry() |>
  dplyr::group_by(USA_ATCFID) |>
  dplyr::summarize(Wmax = max(WMO_WIND, na.rm = TRUE))
```

```{r}
tmap::tmap_mode("view")
tmap::tm_shape(Tracks2.sf) +
  tmap::tm_lines()
```

## Wind field model

<https://github.com/jbcannon/hurrecon/tree/v.0.0.1>

```{r}
devtools::install_github('jbcannon/hurrecon')

library(hurrecon)
path <- here::here("data", "hurdat_data.csv")
fetch_best_tracks_data(path,
                       src = 
"https://www.nhc.noaa.gov/data/hurdat/hurdat2-1851-2023-051124.txt")
```

The last 6 numbers before the `.txt` are the date of the archive. As of 6 June 2024, the archive date is 5 May 2023

Load the data for Hurricane Michael (2018, ID = AL142018) as a simple feature data frame with CRS UTM16 (EPSG 32616)
```{r}
Michael_Track.sf <- load_hurdat_track(path, 
                                      trackID = 'AL142018')
X.sf <- load_hurdat_track(path,
                          trackID = 'AL041851')
```

Get land mask
```{r}
library(terra)
data("geographic")
```

Create raster of winds with units of m/s. This takes a long time (13 minutes on desktop)
```{r}
t0 <- Sys.time()
Wind.r <- hurrecon_run(Michael_Track.sf, 
                       max_rad_km = 100, 
                       res_m = 30000, 
                       max_interp_dist_km = 5)
Sys.time() - t0
```

Make a plot
```{r}
plot(land)
plot(Wind.r, add = TRUE)
plot(land, add = TRUE)
```

Extract the wind speed from the raster at a particular location.

Create the location
```{r}
point <- sf::st_point(c(-85.3, 29.9))
location.sf <- sf::st_sfc(point, 
                           crs = 4326) |>
  sf::st_transform(crs = sf::st_crs(Wind.r)) |>
  sf::st_as_sf()

Wind.r |>
  terra::extract(location.sf)
```


Include only track observations when the track is within 200 km of a location
```{r}
buffer.sf <- location.sf |>
  sf::st_buffer(dist = 200000)

Michael_Track2.sf <- Michael_Track.sf |>
  sf::st_intersection(buffer.sf) 

colnames(Michael_Track2.sf)[11:22] <- colnames(Michael_Track.sf)[11:22]
```

Run the wind field model
```{r}
t0 <- Sys.time()
Wind.r2 <- hurrecon_run(Michael_Track2.sf, 
                        max_rad_km = 100, res_m = 5000, max_interp_dist_km = 5)
Sys.time() - t0
```

32 seconds

```{r}
tmap::tmap_mode("view")
tmap::tm_shape(Wind.r2) +
  tmap::tm_raster(alpha = .5) +
  tmap::tm_shape(Michael_Track.sf) +
    tmap::tm_dots()
```

Multiple storms wind fields for a specific location into a single `SpatVector`.

Get all tracks
```{r}
df <- read.csv(here::here("data", "hurdat_data.csv"))
df$date <- lubridate::ymd(df$date)
df$lon2 <- as.numeric(df$lon)
df$lat2 <- as.numeric(df$lat)
df <- df[complete.cases(df[, c("lon2")]), ]

sdf <- df |>
  sf::st_as_sf(coords = c("lon2", "lat2"))
sf::st_crs(sdf) <- 4326

sdf <- sdf |>
  sf::st_transform(crs = 32616)

sdf[, c("utmx", "utmy")] <- sf::st_coordinates(sdf)

cn <- c("34kt_ne", "34kt_se",	"34kt_sw", "34kt_nw",	
        "50kt_ne", "50kt_se",	"50kt_sw", "50kt_nw",
        "64kt_ne", "64kt_se",	"64kt_sw", "64kt_nw")
colnames(sdf)[11:22] <- cn
```